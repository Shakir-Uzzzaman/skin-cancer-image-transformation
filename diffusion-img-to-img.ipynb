{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10095897,"sourceType":"datasetVersion","datasetId":6226115}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install diffusers accelerate transformers datasets -q\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:34:55.947510Z","iopub.execute_input":"2024-12-04T14:34:55.947817Z","iopub.status.idle":"2024-12-04T14:35:07.499387Z","shell.execute_reply.started":"2024-12-04T14:34:55.947790Z","shell.execute_reply":"2024-12-04T14:35:07.498259Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom diffusers import StableDiffusionImg2ImgPipeline\nfrom transformers import AutoTokenizer\nfrom datasets import load_dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:35:23.693080Z","iopub.execute_input":"2024-12-04T14:35:23.693447Z","iopub.status.idle":"2024-12-04T14:35:41.343467Z","shell.execute_reply.started":"2024-12-04T14:35:23.693418Z","shell.execute_reply":"2024-12-04T14:35:41.342738Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3541460aa484044811a0e71476075dc"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from diffusers import StableDiffusionPipeline\n\nmodel_name = \"CompVis/stable-diffusion-v1-4\"  # Replace with lightweight version\npipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n).to(\"cuda\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:35:49.720532Z","iopub.execute_input":"2024-12-04T14:35:49.720905Z","iopub.status.idle":"2024-12-04T14:36:10.800523Z","shell.execute_reply.started":"2024-12-04T14:35:49.720873Z","shell.execute_reply":"2024-12-04T14:36:10.799492Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d75eb5301dc41e48822290819b4b4e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1717c90112824a0e9a886f804da4df05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2956b6fa0ebd4111aa1971bfcc2d087b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00b7b2f12cc14adca594e165a3393434"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ature_extractor/preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9167e2bb6f642acbc39e98e51b710af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"safety_checker/config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2e21967e4bb4724b3eba05aafa5d2ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler/scheduler_config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aab9495ad7f84dfd9420685d196ade11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)kpoints/scheduler_config-checkpoint.json:   0%|          | 0.00/209 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c88e3ab6cfa41e4908305c56d6f4da5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"100c2a898f0449229c74d48c3c42194f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e907b98067a741b1ab5ac81cfe5832eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"100ab436016448e2a2b9f23f7d60502b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04ecf77c905745388c11738b38c9cdf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet/config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4321b6fba4f04a9ab304d4501b670187"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e2f61c6d74c4bc2b43ca0bd6756ce4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f90f5e22bf0f4287832ebfa41bbd8187"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a67eb6bec64748798851e280dcfe1618"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vae/config.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6944ccfd9ed9475890206a826d396212"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7625e73de8540f6a1a8f6cea24ec0bd"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Define your image folder path\nimage_folder_path = \"/kaggle/input/skin-cancer-img-to-img/all_image_cancer\"\n\n# Preprocessing function\ndef preprocess_image(image_path):\n    image = Image.open(image_path).convert(\"RGB\")\n    return image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:36:51.247604Z","iopub.execute_input":"2024-12-04T14:36:51.248431Z","iopub.status.idle":"2024-12-04T14:36:51.252890Z","shell.execute_reply.started":"2024-12-04T14:36:51.248393Z","shell.execute_reply":"2024-12-04T14:36:51.251848Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load images from the directory\nfrom PIL import Image\nimport os\nimage_files = [os.path.join(image_folder_path, f) for f in os.listdir(image_folder_path) if f.endswith('.jpg') or f.endswith('.png')]\n\n# Preprocess all images\nimages = [preprocess_image(img_path) for img_path in image_files]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:36:54.984224Z","iopub.execute_input":"2024-12-04T14:36:54.984914Z","iopub.status.idle":"2024-12-04T14:37:11.457046Z","shell.execute_reply.started":"2024-12-04T14:36:54.984876Z","shell.execute_reply":"2024-12-04T14:37:11.455960Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Select a sample image for testing (using the first image in the folder)\ninput_image = images[0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:37:33.002409Z","iopub.execute_input":"2024-12-04T14:37:33.002774Z","iopub.status.idle":"2024-12-04T14:37:33.007075Z","shell.execute_reply.started":"2024-12-04T14:37:33.002741Z","shell.execute_reply":"2024-12-04T14:37:33.006109Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Define the prompt\nprompt = \"A high-quality transformation of a skin cancer image\"\n\n# Call the pipeline with the input image and other parameters\nresult = pipeline(prompt=prompt, image=input_image, strength=0.5, guidance_scale=7.5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:37:36.298421Z","iopub.execute_input":"2024-12-04T14:37:36.299265Z","iopub.status.idle":"2024-12-04T14:37:42.057671Z","shell.execute_reply.started":"2024-12-04T14:37:36.299230Z","shell.execute_reply":"2024-12-04T14:37:42.056831Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0fdad922f9241cb9f19fba7cfa1e795"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Print the result to understand its structure\nprint(result)\n\n# Try extracting the image from the correct key\nif \"images\" in result:\n    output_image = result[\"images\"][0]  # Extract the first image from the list\nelse:\n    print(\"Error: 'images' key not found in the result.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:37:44.650905Z","iopub.execute_input":"2024-12-04T14:37:44.651736Z","iopub.status.idle":"2024-12-04T14:37:44.656423Z","shell.execute_reply.started":"2024-12-04T14:37:44.651700Z","shell.execute_reply":"2024-12-04T14:37:44.655422Z"}},"outputs":[{"name":"stdout","text":"StableDiffusionPipelineOutput(images=[<PIL.Image.Image image mode=RGB size=600x448 at 0x7EBCCF011240>], nsfw_content_detected=[False])\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Check if the output image is a valid PIL Image and save it\nif isinstance(output_image, Image.Image):\n    output_image.save(\"output_image.jpg\")\n    print(\"Image saved successfully.\")\nelse:\n    print(\"Error: The result is not a PIL Image object or was not processed correctly.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:37:48.774580Z","iopub.execute_input":"2024-12-04T14:37:48.775167Z","iopub.status.idle":"2024-12-04T14:37:48.782220Z","shell.execute_reply.started":"2024-12-04T14:37:48.775135Z","shell.execute_reply":"2024-12-04T14:37:48.781293Z"}},"outputs":[{"name":"stdout","text":"Image saved successfully.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Save the fine-tuned model\npipeline.save_pretrained(\"./fine_tuned_model\")\nprint(\"Model saved successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:37:52.006920Z","iopub.execute_input":"2024-12-04T14:37:52.007794Z","iopub.status.idle":"2024-12-04T14:37:57.830870Z","shell.execute_reply.started":"2024-12-04T14:37:52.007760Z","shell.execute_reply":"2024-12-04T14:37:57.829718Z"}},"outputs":[{"name":"stdout","text":"Model saved successfully.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from skimage.metrics import structural_similarity as ssim\nimport numpy as np\nfrom PIL import Image\n\n# Function to calculate SSIM between input and generated image\ndef calculate_ssim(input_img, generated_img):\n    # Resize generated image to the same size as the input image\n    generated_img = generated_img.resize(input_img.size)\n    \n    # Convert images to NumPy arrays\n    input_img = np.array(input_img)\n    generated_img = np.array(generated_img)\n    \n    # Calculate SSIM with a smaller window size to avoid errors for small images\n    return ssim(input_img, generated_img, multichannel=True, win_size=3)\n\n# Calculate SSIM between input image and generated image\nssim_value = calculate_ssim(input_image, output_image)\nprint(f\"SSIM: {ssim_value}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:38:06.636222Z","iopub.execute_input":"2024-12-04T14:38:06.636922Z","iopub.status.idle":"2024-12-04T14:38:06.814573Z","shell.execute_reply.started":"2024-12-04T14:38:06.636884Z","shell.execute_reply":"2024-12-04T14:38:06.813682Z"}},"outputs":[{"name":"stdout","text":"SSIM: 0.9010540592630195\n","output_type":"stream"}],"execution_count":11}]}